import json
from pathlib import Path

# –ü—Ä–æ–≤–µ—Ä—è–µ–º JSON
with open('selected_annotations.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

print("=" * 60)
print("–ê–ù–ê–õ–ò–ó selected_annotations.json")
print("=" * 60)

total_docs = len(data)
total_pages = 0
total_annotations = 0

for pdf_name, pdf_data in data.items():
    pages_in_doc = 0
    anns_in_doc = 0
    
    for page_name, page_data in pdf_data.items():
        if page_name.startswith('page_'):
            pages_in_doc += 1
            annotations = page_data.get('annotations', [])
            anns_in_doc += len(annotations)
    
    if anns_in_doc > 0:
        print(f"\nüìÑ {pdf_name}")
        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü: {pages_in_doc}, –ê–Ω–Ω–æ—Ç–∞—Ü–∏–π: {anns_in_doc}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä
        for page_name, page_data in pdf_data.items():
            if page_name.startswith('page_'):
                annotations = page_data.get('annotations', [])
                if annotations:
                    print(f"   –ü—Ä–∏–º–µ—Ä –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏: {annotations[0]}")
                    break
    
    total_pages += pages_in_doc
    total_annotations += anns_in_doc

print("\n" + "=" * 60)
print(f"–ò–¢–û–ì–û:")
print(f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_docs}")
print(f"–°—Ç—Ä–∞–Ω–∏—Ü: {total_pages}")
print(f"–ê–Ω–Ω–æ—Ç–∞—Ü–∏–π: {total_annotations}")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º txt —Ñ–∞–π–ª—ã
print("\n" + "=" * 60)
print("–ü–†–û–í–ï–†–ö–ê .TXT –§–ê–ô–õ–û–í")
print("=" * 60)

train_labels = list(Path('dataset/labels/train').glob('*.txt'))
non_empty = 0

for label_file in train_labels[:5]:  # –ü–µ—Ä–≤—ã–µ 5
    size = label_file.stat().st_size
    print(f"\n{label_file.name}: {size} –±–∞–π—Ç")
    
    if size > 0:
        non_empty += 1
        with open(label_file, 'r') as f:
            content = f.read()
            print(f"  –°–æ–¥–µ—Ä–∂–∏–º–æ–µ: {content[:100]}")

print(f"\n‚úÖ –ù–µ–ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ (–∏–∑ –ø–µ—Ä–≤—ã—Ö 5): {non_empty}")